{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb513c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad584a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- Helper Functions ---\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_stats(data_list):\n",
    "    \"\"\"\n",
    "    Calculating basic statistics for a list of numbers without third-party libraries.\n",
    "    \"\"\"\n",
    "    # Filtering out non-numeric or None values first.\n",
    "    numbers = [x for x in data_list if isinstance(x, (int, float))]\n",
    "    if not numbers:\n",
    "        return {'count': 0, 'mean': 0, 'min': 0, 'max': 0, 'std_dev': 0}\n",
    "\n",
    "    count = len(numbers)\n",
    "    mean = sum(numbers) / count\n",
    "    min_val = min(numbers)\n",
    "    max_val = max(numbers)\n",
    "\n",
    "    # Calculating standard deviation.\n",
    "    sum_sq_diff = sum((x - mean) ** 2 for x in numbers)\n",
    "    std_dev = math.sqrt(sum_sq_diff / count) if count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'count': count, 'mean': f\"{mean:.2f}\", 'min': min_val,\n",
    "        'max': max_val, 'std_dev': f\"{std_dev:.2f}\"\n",
    "    }\n",
    "\n",
    "def parse_row(row_dict, numeric_cols, date_cols):\n",
    "    \"\"\"\n",
    "    Processing a single row (a dictionary) to convert strings to numbers and dates.\n",
    "    \"\"\"\n",
    "    for col, value in row_dict.items():\n",
    "        if col in numeric_cols:\n",
    "            try:\n",
    "                row_dict[col] = int(value)\n",
    "            except (ValueError, TypeError):\n",
    "                try:\n",
    "                    row_dict[col] = float(value)\n",
    "                except (ValueError, TypeError):\n",
    "                    row_dict[col] = None\n",
    "        elif col in date_cols:\n",
    "            try:\n",
    "                # Attempting to parse different datetime formats.\n",
    "                row_dict[col] = datetime.fromisoformat(value.replace('Z', '+00:00'))\n",
    "            except (ValueError, TypeError):\n",
    "                row_dict[col] = None\n",
    "    return row_dict\n",
    "\n",
    "# ==============================================================================\n",
    "# --- Main Analysis Function ---\n",
    "# ==============================================================================\n",
    "\n",
    "def analyze_dataset_pure_python(filepath, numeric_cols, date_cols, group_by_col):\n",
    "    \"\"\"\n",
    "    Loads, processes, and analyzes a dataset using only standard Python libraries.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\\nüîÑ Processing file with Pure Python: {filepath}\\n{'='*60}\")\n",
    "    \n",
    "    # --- Loading and Cleaning Data ---\n",
    "    header, data = [], []\n",
    "    try:\n",
    "        with open(filepath, mode='r', encoding='utf-8', newline='') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            header = next(reader)\n",
    "            for row in reader:\n",
    "                row_dict = dict(zip(header, row))\n",
    "                cleaned_row = parse_row(row_dict, numeric_cols, date_cols)\n",
    "                data.append(cleaned_row)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Handled a reading error: {e}\")\n",
    "\n",
    "    if not data:\n",
    "        print(f\"‚ùå No data loaded from {filepath}.\")\n",
    "        return\n",
    "\n",
    "    # --- 1. High-Level Descriptive Statistics ---\n",
    "    print(\"\\n#### 1. High-Level Descriptive Statistics ####\")\n",
    "    print(f\"Total Rows: {len(data)}\")\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in header:\n",
    "            # CORRECTED LINE: Using row.get(col) to safely access the value.\n",
    "            # This prevents KeyErrors if a row is missing a column.\n",
    "            values = [row.get(col) for row in data]\n",
    "            stats = calculate_stats(values)\n",
    "            print(f\"  - Column '{col}': Mean={stats['mean']}, Max={stats['max']}\")\n",
    "\n",
    "    # --- 2. Single-Column Analysis ---\n",
    "    print(\"\\n#### 2. Single-Column Analysis (Univariate) ####\")\n",
    "    if group_by_col in header:\n",
    "        values = [row.get(group_by_col) for row in data]\n",
    "        counts = Counter(values)\n",
    "        print(f\"Top 5 most common values in '{group_by_col}':\")\n",
    "        for value, count in counts.most_common(5):\n",
    "            print(f\"  - '{value}': {count} times\")\n",
    "\n",
    "    # --- 3. Grouped Analysis ---\n",
    "    print(f\"\\n#### 3. Grouped Analysis by '{group_by_col}' ####\")\n",
    "    grouped_data = defaultdict(list)\n",
    "    for row in data:\n",
    "        if row.get(group_by_col): # Ensuring the group-by key exists.\n",
    "            grouped_data[row[group_by_col]].append(row)\n",
    "    \n",
    "    target_numeric_col = next((col for col in numeric_cols if col in header), None)\n",
    "    \n",
    "    if target_numeric_col:\n",
    "        print(f\"Analyzing '{target_numeric_col}' for each group:\")\n",
    "        group_stats = {}\n",
    "        for group, rows in grouped_data.items():\n",
    "            col_values = [row.get(target_numeric_col) for row in rows]\n",
    "            stats = calculate_stats(col_values)\n",
    "            group_stats[group] = (stats['count'], float(stats['mean']))\n",
    "        \n",
    "        sorted_groups = sorted(group_stats.items(), key=lambda item: item[1][0], reverse=True)\n",
    "        for group, (count, mean) in sorted_groups[:5]:\n",
    "             print(f\"  - Group '{group}': Count={count}, Avg '{target_numeric_col}'={mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964bb90",
   "metadata": {},
   "source": [
    "### Executing Analysis for All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51163240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîÑ Processing file with Pure Python: data/2024_fb_ads_president_scored_anon.csv\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### 1. High-Level Descriptive Statistics ####\n",
      "Total Rows: 31907\n",
      "  - Column 'estimated_spend': Mean=1653.13, Max=474999\n",
      "  - Column 'estimated_impressions': Mean=71890.15, Max=1000000\n",
      "\n",
      "#### 2. Single-Column Analysis (Univariate) ####\n",
      "Top 5 most common values in 'bylines':\n",
      "  - 'HARRIS FOR PRESIDENT': 9687 times\n",
      "  - 'HARRIS VICTORY FUND': 4629 times\n",
      "  - 'DONALD J. TRUMP FOR PRESIDENT 2024, INC.': 4323 times\n",
      "  - 'Working America': 1356 times\n",
      "  - 'Trump National Committee JFC': 1200 times\n",
      "\n",
      "#### 3. Grouped Analysis by 'bylines' ####\n",
      "Analyzing 'estimated_spend' for each group:\n",
      "  - Group 'HARRIS FOR PRESIDENT': Count=9687, Avg 'estimated_spend'=1566.04\n",
      "  - Group 'HARRIS VICTORY FUND': Count=4629, Avg 'estimated_spend'=1428.23\n",
      "  - Group 'DONALD J. TRUMP FOR PRESIDENT 2024, INC.': Count=4323, Avg 'estimated_spend'=1027.68\n",
      "  - Group 'Working America': Count=1355, Avg 'estimated_spend'=1221.69\n",
      "  - Group 'Trump National Committee JFC': Count=1200, Avg 'estimated_spend'=1660.58\n",
      "\n",
      "============================================================\n",
      "üîÑ Processing file with Pure Python: data/2024_fb_posts_president_scored_anon.csv\n",
      "============================================================\n",
      "\n",
      "#### 1. High-Level Descriptive Statistics ####\n",
      "Total Rows: 19009\n",
      "  - Column 'Total Interactions': Mean=2210.15, Max=470087\n",
      "  - Column 'Likes': Mean=2377.70, Max=351979\n",
      "  - Column 'Comments': Mean=901.58, Max=93872\n",
      "  - Column 'Shares': Mean=320.54, Max=76150\n",
      "  - Column 'Post Views': Mean=6485.06, Max=4276477.0\n",
      "\n",
      "#### 2. Single-Column Analysis (Univariate) ####\n",
      "Top 5 most common values in 'Page Category':\n",
      "  - 'PERSON': 9453 times\n",
      "  - 'ACTOR': 3304 times\n",
      "  - 'POLITICIAN': 2595 times\n",
      "  - '': 2472 times\n",
      "  - 'POLITICAL_CANDIDATE': 1161 times\n",
      "\n",
      "#### 3. Grouped Analysis by 'Page Category' ####\n",
      "Analyzing 'Total Interactions' for each group:\n",
      "  - Group 'PERSON': Count=7791, Avg 'Total Interactions'=228.44\n",
      "  - Group 'ACTOR': Count=3104, Avg 'Total Interactions'=137.63\n",
      "  - Group 'POLITICIAN': Count=694, Avg 'Total Interactions'=309.19\n",
      "  - Group 'POLITICAL_CANDIDATE': Count=313, Avg 'Total Interactions'=180.12\n",
      "  - Group 'ENTREPRENEUR': Count=23, Avg 'Total Interactions'=139.30\n",
      "\n",
      "============================================================\n",
      "üîÑ Processing file with Pure Python: data/2024_tw_posts_president_scored_anon.csv\n",
      "============================================================\n",
      "\n",
      "#### 1. High-Level Descriptive Statistics ####\n",
      "Total Rows: 27304\n",
      "  - Column 'retweetCount': Mean=1322.06, Max=144615\n",
      "  - Column 'replyCount': Mean=1063.79, Max=121270\n",
      "  - Column 'likeCount': Mean=6913.69, Max=915221\n",
      "  - Column 'viewCount': Mean=507084.73, Max=333502775\n",
      "\n",
      "#### 2. Single-Column Analysis (Univariate) ####\n",
      "Top 5 most common values in 'source':\n",
      "  - 'Twitter Web App': 14930 times\n",
      "  - 'Twitter for iPhone': 8494 times\n",
      "  - 'Sprout Social': 2933 times\n",
      "  - 'Twitter Media Studio': 499 times\n",
      "  - 'Twitter for iPad': 266 times\n",
      "\n",
      "#### 3. Grouped Analysis by 'source' ####\n",
      "Analyzing 'retweetCount' for each group:\n",
      "  - Group 'Twitter Web App': Count=14930, Avg 'retweetCount'=1317.11\n",
      "  - Group 'Twitter for iPhone': Count=8494, Avg 'retweetCount'=612.62\n",
      "  - Group 'Sprout Social': Count=2933, Avg 'retweetCount'=3524.79\n",
      "  - Group 'Twitter Media Studio': Count=499, Avg 'retweetCount'=1586.21\n",
      "  - Group 'Twitter for iPad': Count=266, Avg 'retweetCount'=65.38\n"
     ]
    }
   ],
   "source": [
    "# --- Facebook Ads Analysis ---\n",
    "fb_ads_filepath = 'data/2024_fb_ads_president_scored_anon.csv'\n",
    "fb_ads_numeric = ['estimated_spend', 'estimated_impressions', 'platform_count']\n",
    "fb_ads_dates = ['ad_creation_time']\n",
    "analyze_dataset_pure_python(fb_ads_filepath, fb_ads_numeric, fb_ads_dates, 'bylines')\n",
    "\n",
    "# --- Facebook Posts Analysis ---\n",
    "fb_posts_filepath = 'data/2024_fb_posts_president_scored_anon.csv'\n",
    "fb_posts_numeric = ['Total Interactions', 'Likes', 'Comments', 'Shares', 'Post Views']\n",
    "fb_posts_dates = ['Post Created Date']\n",
    "analyze_dataset_pure_python(fb_posts_filepath, fb_posts_numeric, fb_posts_dates, 'Page Category')\n",
    "\n",
    "# --- Twitter Posts Analysis ---\n",
    "tw_posts_filepath = 'data/2024_tw_posts_president_scored_anon.csv'\n",
    "tw_posts_numeric = ['retweetCount', 'replyCount', 'likeCount', 'viewCount']\n",
    "tw_posts_dates = ['createdAt']\n",
    "analyze_dataset_pure_python(tw_posts_filepath, tw_posts_numeric, tw_posts_dates, 'source')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
